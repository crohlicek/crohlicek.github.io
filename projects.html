<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Dosis:wght@400&display=swap">
    <link rel="stylesheet" href="css/style.css">

    <script src="https://kit.fontawesome.com/41807ab84b.js" crossorigin="anonymous"></script>

    <title>Chris Rohlicek - Projects</title>
</head>
<body>

    <div id="header" class="container-fluid">
        <div class="row">
            <div class="col-6 justify-content-start align-self-center"> 
                <h1 id="my_name">Projects</h1>
                <h5>
                    &nbsp; <a href="rohlicek_cv.pdf">Resume</a> &nbsp; | &nbsp; <a href="index.html">Home</a>
                </h5>
    
            </div>
            <div class="col-6 d-flex justify-content-end"> 
                <img src="images/Linkedin_photo.jpg" alt=“Profile Picture” width="135" height="150" class="myimg"/>
            </div>
        </div>
    </div>


    <div id="content-wrap" class="container-fluid">
        <div id="content-wrap" class="row"> 
            <div class="col-8 justify-content-start"> 
                <p style="font-size:25px; font-style: italic">A deep learning framework for structural variant discovery and genotyping - <a class="inline_link" href=https://www.biorxiv.org/content/10.1101/2022.04.30.490167v1.full.pdf>[bioRxiv]</a></p> 
                <p style="font-size:16px;">Since arriving at the Broad Institute I've been helping out with this paper that describes one of the lab's first major projects - a deep learning structural variant caller. The problem of detecting mutations in the genome is one that is widely approached with tools that implement a set of hand-crafted heuristics for what sequencing reads will look like under the conditions of various mutations. By virtue of the limitations of these kinds of rule-based systems and of the paucity of validated structural variant datasets that are out there, this tool makes an important step forward in shifting the field towards data-driven approaches that are extensible to different kinds of events and sequencing technologies. For more information, here is <a class="inline_link" href=https://www.youtube.com/watch?v=EVlLqig3qEI&list=PLlMMtlgw6qNjROoMNTBQjAcdx53kV50cS&ab_channel=BroadInstitute>the recording of a talk</a> my supervisor and I gave about the framework at Broad's Models, Inference and Algorithms seminar.</p>

                <p style="font-size:25px; font-style: italic">Dynamical Systems Reduction in Experimental Brain Modeling - <a style="font-style: normal" href=https://github.com/crohlicek/brain_modeling>[GitHub]</a></p> 
                <p style="font-size:16px;">Throughout my Master's I did research at the Institute for Brain Science at Brown studying methods of dynamical systems reduction in models of neural spiking behavior. Dimensionality reduction is especially important for modeling neural phenomena because brain activity is typically measured in such a high-dimensional space that simulating the dynamics of the full system can be impractical. To simplify the problem, people try to find ways of identifying simplified systems that exhibit the same intrinsic dynamics that are observed in the data, and conduct simulations on the simplified model as a proxy for the original one. My work focused on dimensionality reduction techniques using recurrent neural networks, and became the subject of my Master's capstone project for my program.</p>

                <p style="font-size:25px; font-style: italic">Neural Network Parameter Reduction Using Pruning and Matrix Decomposition - <a style="font-style: normal" href=https://github.com/crohlicek/model_size_reduction/blob/master/18_065_Final_Project_Report.pdf>[GitHub]</a></p> 
                <p style="font-size:16px;">For this project I was inspired by a lecture I heard by Jonathan Frankle on his work in <a class="inline_link" href=https://arxiv.org/pdf/1803.03635.pdf>The Lottery Ticket Hypothesis</a>. I'm such a fan of this paper because I'm a strong believer in focusing less on what can be accomplished with a huge clumsy neural network, and more on what underlying subtlety makes simple networks so powerful. In my project, I implemented some experiments to compare basic magnitude-based pruning to other methods based on matrix decomposition and dimensionality-reduction techniques applied to the different layers of a network.</p>

                <p style="font-size:25px; font-style: italic">What's a Gaussian Process? - <a style="font-style: normal" href="gp_blog.html">[Post]</a></p>
                <p style="font-size:16px;"> As part of a statistics and machine learning class I took in my Master's program I wrote a blog post about Gaussian process regression, which is a topic that sheds light on an important philosophical point of statistical machine learning - the ability to preserve information about the uncertainty with which we make predictions. Gaussian processes are at the core of a lot of really interesting machine learning research and while they can come off as intimidating, they're fundamentally intuitive objects that leverage Gaussian assumptions to give a highly interpretable and programmable family of models.</p>

                <p style="font-size:25px; font-style: italic">Predicting Voting Behavior of Supreme Court Nominees - <a style="font-style: normal" href=images/SCOTUS_paper.pdf>[PDF]</a></p>
                <p style="font-size:16px;">In my junior year I took a great course in decision theory, which culminated in this group project in which two friends and I set out on the task of predicting the voting patterns of Supreme Court nominees. This project was a substantial data engineering undertaking, involving the processing of raw text data from the judges' confirmation hearings, and demographic data available at the time of confirmation. In this paper we compared logistic regression and random forest models trained on combinations of these real-world data. </p>

                <p style="font-size:25px; font-style: italic">Elliptic Curves and Cryptography - <a style="font-style: normal" href=images/cryptography_paper.pdf>[PDF]</a></p>
                <p style="font-size:16px;">In my sophomore year algebra course I had a chance to write an open-ended paper for which I took inspiration from the controversial <a class="inline_link" href=https://en.wikipedia.org/wiki/FBI%E2%80%93Apple_encryption_dispute>FBI order on Apple</a> to encode a crytographic backdoor into their phones. In this survey paper I write about the use of elliptic curves in pseudo-random number generators, the discrete logarithm problem, and the Diffie-Hellman key exchange.</p>
            </div>
            
        </div>
    </div>

    <footer class="footer">
        <div class="row">
            <div class="col-6 d-flex">
                crohlice[at]broadinstitute[dot]org
            </div>
            <div class="col-6 d-flex justify-content-end">
                <span>
                    <a class="icon-link" href=https://www.linkedin.com/in/chris-rohlicek/ >
                        <i class="fab fa-linkedin"></i>
                    </a>
                    <a class="icon-link" href=https://github.com/crohlicek/>
                        <i class="fab fa-github"></i>
                    </a>
                </span>
            </div>
        </div>
    </footer>

</body>
</html>

